df_error <- 12
alpha <- 0.05
# Using R's qf function to get the critical F-value from the F-distribution
F_critical <- qf(1 - alpha, df1 = df_regression, df2 = df_error)
F_critical  # This will display the critical F-value
# Compare the calculated F-statistic with the critical F-value to decide on the hypothesis
if (F_calculated > F_critical) {
print("Reject the null hypothesis: There is a significant relationship between the variables.")
} else {
print("Do not reject the null hypothesis: There is no significant relationship between the variables.")
}
# Define the number of observations and predictors
n <- 16  # Total number of observations
p <- 3   # Number of predictors
# Extract the sum of squares from the ANOVA table
SSR <- 2074.8654  # Sum of Squares due to Regression
SSTO <- 2270.9375  # Total Sum of Squares
SSE <- 196.0721  # Sum of Squares due to Error
# Calculate the coefficient of multiple determination (R-squared)
R_squared <- SSR / SSTO
# Calculate the adjusted R-squared
R_squared_adjusted <- 1 - ((SSE / SSTO) * ((n - 1) / (n - p - 1)))
# Print the calculated values for verification
cat("Calculated R-squared: ", R_squared, "\n")
cat("Calculated Adjusted R-squared: ", R_squared_adjusted, "\n")
# Compare with summary output from the regression model
summary_stats <- summary(model)
cat("From summary(model): R-squared = ", summary_stats$r.squared, ", Adjusted R-squared = ", summary_stats$adj.r.squared, "\n")
# Summarize the model to get coefficients and standard errors
summary_stats <- summary(model)
# Display the coefficients table
print(summary_stats$coefficients)
# Define the significance level
alpha <- 0.05
# Determine the critical t-value for two-tailed test with 12 degrees of freedom
df <- n - length(coef(model))  # Assuming n = 16, number of predictors p = 3
t_critical <- qt(1 - alpha/2, df)
# Function to perform the t-test for each predictor
perform_t_test <- function(beta, stderr, t_critical) {
t_value <- beta / stderr
if (abs(t_value) > t_critical) {
return(paste("Reject H0. |t| =", abs(t_value), "is greater than t_critical =", t_critical))
} else {
return(paste("Do not reject H0. |t| =", abs(t_value), "is not greater than t_critical =", t_critical))
}
}
# Apply the t-test for each parameter
t_test_results <- sapply(1:3, function(i) perform_t_test(
beta = summary_stats$coefficients[i, "Estimate"],
stderr = summary_stats$coefficients[i, "Std. Error"],
t_critical = t_critical
))
# Print the results
names(t_test_results) <- c("Moisture", "Sweetness", "Calories")
print(t_test_results)
# Extracting model coefficients and their standard errors
coefficients <- summary(model)$coefficients
estimates <- coefficients[, "Estimate"]
std_errors <- coefficients[, "Std. Error"]
# Calculate t-values
t_values <- estimates / std_errors
# Get critical t-value for a two-sided test at alpha = 0.05 with 12 degrees of freedom
alpha <- 0.05
df <- n - length(coefficients[, "Estimate"])  # Adjust this based on your exact number of observations
t_critical <- qt(1 - alpha / 2, df)
# Compare t-values with the critical t-value
conclusions <- abs(t_values) > t_critical
# Print results
print(data.frame(
Coefficient = names(estimates),
Estimate = estimates,
Std_Error = std_errors,
t_value = t_values,
Conclusion = ifelse(conclusions, "Reject H0", "Do not reject H0")
))
# Fit the model
model <- lm(brand ~ moisture + sweetness + calories, data = data)
# Get the summary of the model
summary_stats <- summary(model)
# Extract coefficients
coefficients <- summary_stats$coefficients
# Define significance level
alpha <- 0.05
# Degrees of freedom for t-test
df <- summary_stats$df[2]  # residual degrees of freedom from the model summary
# Critical t-value for two-tailed test at alpha = 0.05
t_critical <- qt(1 - alpha/2, df)
# Function to perform manual t-test
manual_t_test <- function(coef_estimate, coef_stderr, coef_name) {
t_value <- coef_estimate / coef_stderr
p_value <- 2 * pt(-abs(t_value), df)  # two-sided p-value
# Hypotheses
cat(sprintf("Testing %s:\n", coef_name))
cat("H0: The coefficient is equal to 0 (no effect)\n")
cat("Ha: The coefficient is not equal to 0 (has an effect)\n")
# Test statistic
cat(sprintf("t-value: %f\n", t_value))
# Rejection rule
cat(sprintf("Critical t-value at alpha = %f: +/- %f\n", alpha, t_critical))
# Conclusion
if (abs(t_value) > t_critical) {
cat("Conclusion: Reject H0, there is a significant effect.\n\n")
} else {
cat("Conclusion: Do not reject H0, there is no significant effect.\n\n")
}
}
# Apply the t-test for each predictor
sapply(2:nrow(coefficients), function(i) {  # assuming the first row is the intercept
manual_t_test(coefficients[i, "Estimate"], coefficients[i, "Std. Error"], rownames(coefficients)[i])
})
# Extract coefficients
coefficients <- summary_stats$coefficients
# Define significance level
alpha <- 0.05
# Degrees of freedom for t-test
df <- summary_stats$df[2]  # residual degrees of freedom from the model summary
# Critical t-value for two-tailed test at alpha = 0.05
t_critical <- qt(1 - alpha/2, df)
# Function to perform manual t-test
manual_t_test <- function(coef_estimate, coef_stderr, coef_name) {
t_value <- coef_estimate / coef_stderr
p_value <- 2 * pt(-abs(t_value), df)  # two-sided p-value
# Hypotheses
cat(sprintf("Testing %s:\n", coef_name))
cat("H0: The coefficient is equal to 0 (no effect)\n")
cat("Ha: The coefficient is not equal to 0 (has an effect)\n")
# Test statistic
cat(sprintf("t-value: %f\n", t_value))
# Rejection rule
cat(sprintf("Critical t-value at alpha = %f: +/- %f\n", alpha, t_critical))
# Conclusion
if (abs(t_value) > t_critical) {
cat("Conclusion: Reject H0, there is a significant effect.\n\n")
} else {
cat("Conclusion: Do not reject H0, there is no significant effect.\n\n")
}
}
# Apply the t-test for each predictor
sapply(2:nrow(coefficients), function(i) {  # assuming the first row is the intercept
manual_t_test(coefficients[i, "Estimate"], coefficients[i, "Std. Error"], rownames(coefficients)[i])
})
# Extract necessary values
coefficients <- summary_stats$coefficients
residual_df <- summary_stats$df[2]
stderr <- coefficients[, "Std. Error"]
estimates <- coefficients[, "Estimate"]
# Calculate critical t-value for 95% CI
alpha <- 0.05
t_critical <- qt(1 - alpha / 2, residual_df)
# Calculate individual confidence intervals
ci <- sweep(estimates[2:4, , drop = FALSE], 2, t_critical * stderr[2:4], `*`)
# Extract necessary values
coefficients <- coef(summary(model))  # Using coef(summary(model)) to correctly extract coefficients
estimates <- coefficients[, "Estimate"]
stderr <- coefficients[, "Std. Error"]
# Calculate critical t-value for 95% CI
alpha <- 0.05
residual_df <- summary_stats$df[2]
t_critical <- qt(1 - alpha / 2, residual_df)
# Calculate individual confidence intervals for each predictor
ci_individual <- sapply(2:4, function(i) {
estimate <- estimates[i]
error <- stderr[i]
lower <- estimate - t_critical * error
upper <- estimate + t_critical * error
c(lower, upper)
})
# Display individual confidence intervals
print(ci_individual)
# Adjust alpha for Bonferroni correction and calculate confidence intervals
alpha_adj <- alpha / 3
t_critical_bonferroni <- qt(1 - alpha_adj / 2, residual_df)
ci_bonferroni <- sapply(2:4, function(i) {
estimate <- estimates[i]
error <- stderr[i]
lower <- estimate - t_critical_bonferroni * error
upper <- estimate + t_critical_bonferroni * error
c(lower, upper)
})
# Display Bonferroni-adjusted confidence intervals
print(ci_bonferroni)
# Calculate and compare widths of the confidence intervals
widths_individual <- ci_individual[2,] - ci_individual[1,]
widths_bonferroni <- ci_bonferroni[2,] - ci_bonferroni[1,]
print(data.frame(Individual = widths_individual, Bonferroni = widths_bonferroni))
# Compare with built-in R function
ci_builtin <- confint(model, level = 0.95)
print(ci_builtin[2:4, ])
# Assuming the model and summary have been defined
model <- lm(brand ~ moisture + sweetness + calories, data = data)
summary_stats <- summary(model)
coefficients <- coef(summary_stats)
n <- nrow(data)
p <- length(coefficients) - 1  # minus 1 for intercept
alpha <- 0.05
# Individual CIs
t_critical_individual <- qt(1 - alpha / 2, df = n - p)
individual_CIs <- sweep(coefficients[2:4, "Estimate", drop = FALSE], 2,
t_critical_individual * coefficients[2:4, "Std. Error"], `*`)
individual_CIs <- t(sweep(individual_CIs, 1, coefficients[2:4, "Estimate"], `+`))
# Bonferroni-adjusted CIs
t_critical_bonferroni <- qt(1 - (alpha / (2 * p)), df = n - p)
bonferroni_CIs <- sweep(coefficients[2:4, "Estimate", drop = FALSE], 2,
t_critical_bonferroni * coefficients[2:4, "Std. Error"], `*`)
bonferroni_CIs <- t(sweep(bonferroni_CIs, 1, coefficients[2:4, "Estimate"], `+`))
# Output results
print("Individual Confidence Intervals:")
print(individual_CIs)
print("Bonferroni-adjusted Confidence Intervals:")
print(bonferroni_CIs)
# Load necessary library
library(stats)
# Fit the models
model_full <- lm(Y ~ X1 + X2 + X3, data = data)
# Fit models for each hierarchy
model_X1 <- lm(brand ~ moisture, data = data)  # Model with X1 only
model_X1_X2 <- lm(brand ~ moisture + sweetness, data = data)  # Model with X1 and X2
model_full <- lm(brand ~ moisture + sweetness + calories, data = data)  # Full model including X3
# Generate ANOVA tables for model comparisons
anova_X1 <- anova(model_X1)
anova_X1_X2 <- anova(model_X1, model_X1_X2)  # Compares model_X1 and model_X1_X2
anova_full <- anova(model_X1_X2, model_full)  # Compares model_X1_X2 and model_full
# Extract SSR values
SSR_X1 <- anova_X1$"Sum Sq"[1]  # Sum of Squares for moisture
SSR_X2_given_X1 <- anova_X1_X2$"Sum Sq"[2]  # Additional Sum of Squares for sweetness given moisture
SSR_X3_given_X1_X2 <- anova_full$"Sum Sq"[2]  # Additional Sum of Squares for calories given moisture and sweetness
SSR_X1_X2 <- sum(anova_X1_X2[c(1,2), "Sum Sq"])  # Combined Sum of Squares for moisture and sweetness
# Print results
cat("SSR(X1) - moisture only:", SSR_X1, "\n")
cat("SSR(X2|X1) - sweetness given moisture:", SSR_X2_given_X1, "\n")
cat("SSR(X3|X1, X2) - calories given moisture and sweetness:", SSR_X3_given_X1_X2, "\n")
cat("SSR(X1, X2) - combined moisture and sweetness:", SSR_X1_X2, "\n")
# Given values from ANOVA table
SSR_X1 <- 1739.11
SSR_X2_given_X1 <- 333.06
SSR_X3_given_X1_X2 <- 2.69
# Calculating combined SSR(X1, X2)
SSR_X1_X2 <- SSR_X1 + SSR_X2_given_X1
# Output results
cat("SSR(X1) - Moisture only: ", SSR_X1, "\n")
cat("SSR(X2|X1) - Sweetness given Moisture: ", SSR_X2_given_X1, "\n")
cat("SSR(X3|X1, X2) - Calories given Moisture and Sweetness: ", SSR_X3_given_X1_X2, "\n")
cat("SSR(X1, X2) - Combined Moisture and Sweetness: ", SSR_X1_X2, "\n")
# Assuming 'data' is your DataFrame containing the variables
model_X2_X3_X1 <- lm(brand ~ sweetness + calories + moisture, data = data)
# Generate ANOVA table for the model
anova_result <- anova(model_X2_X3_X1)
print(anova_result)
# Extract SSR values directly
SSR_X2 <- anova_result$"Sum Sq"[1]  # Sum of squares for X2
SSR_X3_given_X2 <- anova_result$"Sum Sq"[2]  # Sum of squares for X3 given X2
SSR_X1_given_X2_X3 <- anova_result$"Sum Sq"[3]  # Sum of squares for X1 given X2 and X3
SSR_X2_X3 <- SSR_X2 + SSR_X3_given_X2  # Combined sum of squares for X2 and X3
# Print the results
cat("SSR(X2):", SSR_X2, "\n")
cat("SSR(X3|X2):", SSR_X3_given_X2, "\n")
cat("SSR(X1|X2, X3):", SSR_X1_given_X2_X3, "\n")
cat("SSR(X2, X3):", SSR_X2_X3, "\n")
model_X2_X3_X1 <- lm(brand ~ sweetness + calories + moisture, data = data)
# Generate ANOVA table for the model
anova_result <- anova(model_X2_X3_X1)
print(anova_result)
# Extract SSR values directly
SSR_X2 <- anova_result$"Sum Sq"[1]  # Sum of squares for X2
SSR_X3_given_X2 <- anova_result$"Sum Sq"[2]  # Sum of squares for X3 given X2
SSR_X1_given_X2_X3 <- anova_result$"Sum Sq"[3]  # Sum of squares for X1 given X2 and X3
SSR_X2_X3 <- SSR_X2 + SSR_X3_given_X2  # Combined sum of squares for X2 and X3
# Print the results
cat("SSR(X2):", SSR_X2, "\n")
cat("SSR(X3|X2):", SSR_X3_given_X2, "\n")
cat("SSR(X1|X2, X3):", SSR_X1_given_X2_X3, "\n")
cat("SSR(X2, X3):", SSR_X2_X3, "\n")
model_X1 <- lm(brand ~ moisture, data = data)  # Model for moisture
model_X2 <- lm(brand ~ sweetness, data = data)  # Model for sweetness
model_X3 <- lm(brand ~ calories, data = data)  # Model for calories
model_X1_X2 <- lm(brand ~ moisture + sweetness, data = data)  # Moisture and sweetness
model_X1_X3 <- lm(brand ~ moisture + calories, data = data)  # Moisture and calories
model_X2_X3 <- lm(brand ~ sweetness + calories, data = data)  # Sweetness and calories
model_full <- lm(brand ~ moisture + sweetness + calories, data = data)
# Calculate partial R^2
# These require sequential models as seen in the Chapter 7 examples, typically using an ANOVA approach
anova_partial <- anova(model_X2, model_X2_X3)
R2_3_given_2 <- anova_partial$"Sum Sq"[2] / sum(anova(model_full)$"Sum Sq")  # Unique contribution of calories given sweetness
anova_partial <- anova(model_X1, model_X1_X3)
R2_3_given_1 <- anova_partial$"Sum Sq"[2] / sum(anova(model_full)$"Sum Sq")  # Unique contribution of calories given moisture
# Extract R-squared from each model summary
R1_squared <- summary(model_X1)$r.squared
R2_squared <- summary(model_X2)$r.squared
R3_squared <- summary(model_X3)$r.squared
R12_squared <- summary(model_X1_X2)$r.squared
R13_squared <- summary(model_X1_X3)$r.squared
R23_squared <- summary(model_X2_X3)$r.squared
# Display results
cat("R1^2:", R1_squared, "\n",
"R2^2:", R2_squared, "\n",
"R3^2:", R3_squared, "\n",
"R12^2:", R12_squared, "\n",
"R13^2:", R13_squared, "\n",
"R23^2:", R23_squared, "\n",
"R2|3^2:", R2_3_given_2, "\n",
"R3|1^2:", R2_3_given_1, "\n")
model_X1 <- lm(brand ~ moisture, data = data)  # Model for moisture
model_X2 <- lm(brand ~ sweetness, data = data)  # Model for sweetness
model_X3 <- lm(brand ~ calories, data = data)  # Model for calories
model_X1_X2 <- lm(brand ~ moisture + sweetness, data = data)  # Moisture and sweetness
model_X1_X3 <- lm(brand ~ moisture + calories, data = data)  # Moisture and calories
model_X2_X3 <- lm(brand ~ sweetness + calories, data = data)  # Sweetness and calories
model_full <- lm(brand ~ moisture + sweetness + calories, data = data)
# Calculate partial R^2
anova_partial <- anova(model_X2, model_X2_X3)
R2_3_given_2 <- anova_partial$"Sum Sq"[2] / sum(anova(model_full)$"Sum Sq")
anova_partial <- anova(model_X1, model_X1_X3)
R2_3_given_1 <- anova_partial$"Sum Sq"[2] / sum(anova(model_full)$"Sum Sq")
# Extract R-squared from each model summary
R1_squared <- summary(model_X1)$r.squared
R2_squared <- summary(model_X2)$r.squared
R3_squared <- summary(model_X3)$r.squared
R12_squared <- summary(model_X1_X2)$r.squared
R13_squared <- summary(model_X1_X3)$r.squared
R23_squared <- summary(model_X2_X3)$r.squared
# Display results
cat("R1^2:", R1_squared, "\n",
"R2^2:", R2_squared, "\n",
"R3^2:", R3_squared, "\n",
"R12^2:", R12_squared, "\n",
"R13^2:", R13_squared, "\n",
"R23^2:", R23_squared, "\n",
"R2|3^2:", R2_3_given_2, "\n",
"R3|1^2:", R2_3_given_1, "\n")
# Load necessary library
library(stats)
# Fit models for individual predictors
model_X1 <- lm(brand ~ moisture, data = data)
model_X2 <- lm(brand ~ sweetness, data = data)
model_X3 <- lm(brand ~ calories, data = data)
# Fit models for pairs of predictors
model_X1_X2 <- lm(brand ~ moisture + sweetness, data = data)
model_X1_X3 <- lm(brand ~ moisture + calories, data = data)
model_X2_X3 <- lm(brand ~ sweetness + calories, data = data)
# Fit the full model with all predictors
model_full <- lm(brand ~ moisture + sweetness + calories, data = data)
# Calculate R^2 for individual predictors
R1_squared <- summary(model_X1)$r.squared
R2_squared <- summary(model_X2)$r.squared
R3_squared <- summary(model_X3)$r.squared
# Calculate R^2 for pairs of predictors
R12_squared <- summary(model_X1_X2)$r.squared
R13_squared <- summary(model_X1_X3)$r.squared
R23_squared <- summary(model_X2_X3)$r.squared
# Full model R^2
R_full_squared <- summary(model_full)$r.squared
# Calculate partial R^2 values
R1_given_23 <- (R_full_squared - R23_squared) / (1 - R23_squared)
R2_given_13 <- (R_full_squared - R13_squared) / (1 - R13_squared)
R3_given_12 <- (R_full_squared - R12_squared) / (1 - R12_squared)
cat("R1^2: ", R1_squared, "\n",
"R2^2: ", R2_squared, "\n",
"R3^2: ", R3_squared, "\n",
"R12^2: ", R12_squared, "\n",
"R13^2: ", R13_squared, "\n",
"R23^2: ", R23_squared, "\n",
"R1|23^2: ", R1_given_23, "\n",
"R2|13^2: ", R2_given_13, "\n",
"R3|12^2: ", R3_given_12, "\n")
# Load necessary library
library(stats)
# Fit the full model with all predictors
model_full <- lm(brand ~ moisture + sweetness + calories, data = data)
# Fit the reduced model without X2 and X3
model_reduced <- lm(brand ~ moisture, data = data)
# Perform ANOVA to compare the two models
model_comparison <- anova(model_reduced, model_full)
# Calculate the F-statistic
SSE_reduced <- sum(model_reduced$residuals^2)
SSE_full <- sum(model_full$residuals^2)
df_reduced <- df.residual(model_reduced)
df_full <- df.residual(model_full)
numerator_df <- (SSE_reduced - SSE_full)
denominator_df <- df_reduced - df_full
F_statistic <- (numerator_df / 2) / (SSE_full / df_full)
# Find the critical F-value for alpha = 0.05
F_critical <- qf(0.95, df1 = 2, df2 = df_full)
# Output the calculated F-statistic and critical F-value
cat("Calculated F-statistic: ", F_statistic, "\n")
cat("Critical F-value at alpha = 0.05: ", F_critical, "\n")
# State the rejection rule and conclusion
if (F_statistic > F_critical) {
cat("Reject H0: At least one of X2 or X3 significantly contributes to the model.\n")
} else {
cat("Do not reject H0: X2 and X3 do not significantly contribute to the model.\n")
}
# Load necessary library
library(stats)
# Fit the full model with all predictors
full_model <- lm(brand ~ moisture + sweetness + calories, data = data)
# Fit the reduced model without X3
reduced_model <- lm(brand ~ moisture + sweetness, data = data)
# Perform ANOVA to compare the two models
model_comparison <- anova(reduced_model, full_model)
# Extract the F-statistic from the ANOVA comparison
# Assume the second row relates to the addition of X3
F_statistic <- model_comparison$"F"[2]
# Calculate the degrees of freedom for the numerator and denominator
df_numerator <- model_comparison$"Df"[2]  # Degrees of freedom for X3
df_denominator <- model_comparison$"Residual Df"[2]  # Error degrees of freedom from the full model
# Calculate the critical F-value for alpha = 0.05
F_critical <- qf(0.95, df1 = df_numerator, df2 = df_denominator)
# Load the necessary library
library(stats)
# Define the full model with all three predictors
full_model <- lm(brand ~ moisture + sweetness + calories, data = data)
# Define the reduced model without X3 (calories)
reduced_model <- lm(brand ~ moisture + sweetness, data = data)
# Perform the ANOVA to compare the full model with the reduced model
model_comparison <- anova(reduced_model, full_model)
# Extract the sum of squares and degrees of freedom for the added variable (X3)
ssq_diff <- model_comparison$"Sum Sq"[2]  # Sum of Squares due to X3
df_diff <- model_comparison$"Df"[2]       # Degrees of freedom associated with X3
residual_df_full <- model_comparison$"Residual Df"[2]  # Residual degrees of freedom for the full model
# Calculate the F-statistic
F_statistic <- (ssq_diff / df_diff) / (model_comparison$"Resid. SS"[2] / residual_df_full)
# Calculate the critical F-value using the F-distribution
F_critical <- qf(0.95, df1 = df_diff, df2 = residual_df_full)
# Load necessary library
library(stats)
# Define the full and reduced models
full_model <- lm(brand ~ moisture + sweetness + calories, data = data)
reduced_model <- lm(brand ~ moisture + sweetness, data = data)
# Perform the ANOVA to compare the models
model_comparison <- anova(reduced_model, full_model)
# Check the model_comparison output
print(model_comparison)
# Calculate the F-statistic manually
ssq_diff <- model_comparison$"Sum Sq"[2]  # Sum of Squares for X3
df_diff <- model_comparison$"Df"[2]       # Degrees of freedom for X3
residual_df_full <- model_comparison$"Resid. Df"[2]  # Residual degrees of freedom for the full model
# Calculate the F-statistic
F_statistic <- (ssq_diff / df_diff) / (model_comparison$"Resid. SS"[2] / residual_df_full)
# Correct the F-critical calculation
F_critical <- qf(0.95, df1 = df_diff, df2 = residual_df_full)
# Load necessary library
library(stats)
# Define the full and reduced models
full_model <- lm(brand ~ moisture + sweetness + calories, data = data)
reduced_model <- lm(brand ~ moisture + sweetness, data = data)
# Perform the ANOVA to compare the models
model_comparison <- anova(reduced_model, full_model)
# Print the ANOVA table to check the output
print(model_comparison)
# Assuming the correct rows are being accessed,
# Extract the F-statistic directly from the ANOVA comparison (if it is provided)
F_statistic <- model_comparison$F[2]  # This needs checking against the actual output
# Ensure the degrees of freedom for the numerator and denominator are correctly retrieved
df_numerator <- model_comparison$Df[2]  # Change indices if needed based on the printed table
residual_df_full <- model_comparison$`Res.Df`[2]  # Residual degrees of freedom for the full model
# Calculate the critical F-value
F_critical <- qf(0.95, df1 = df_numerator, df2 = residual_df_full)
# Output the F-statistic and critical F-value
cat("Calculated F-statistic: ", F_statistic, "\n")
cat("Critical F-value at alpha = 0.05: ", F_critical, "\n")
# Decision Rule: Reject H0 if F_statistic > F_critical
if (F_statistic > F_critical) {
cat("Reject H0: X3 significantly contributes to the model.\n")
} else {
cat("Do not reject H0: X3 does not significantly contribute to the model.\n")
}
# Load model if not already loaded
model <- lm(brand ~ moisture + sweetness + calories, data = data)
# Extract estimates, standard errors, and degrees of freedom
summary_model <- summary(model)
betas <- summary_model$coefficients[2:4, 1]         # β1, β2, β3
std_errors <- summary_model$coefficients[2:4, 2]    # SEs
df <- summary_model$df[2]                           # Degrees of freedom (n - p - 1)
# ---- Individual 95% Confidence Intervals ----
alpha <- 0.05
t_indiv <- qt(1 - alpha/2, df)
lower_indiv <- betas - t_indiv * std_errors
upper_indiv <- betas + t_indiv * std_errors
individual_CIs <- data.frame(
Coefficient = c("moisture", "sweetness", "calories"),
Lower = lower_indiv,
Upper = upper_indiv,
Width = upper_indiv - lower_indiv
)
cat("Individual 95% Confidence Intervals:\n")
print(individual_CIs)
# ---- Bonferroni-adjusted Joint 95% Confidence Intervals ----
m <- 3  # number of parameters
alpha_bonf <- alpha / m
t_bonf <- qt(1 - alpha_bonf/2, df)
lower_bonf <- betas - t_bonf * std_errors
upper_bonf <- betas + t_bonf * std_errors
bonferroni_CIs <- data.frame(
Coefficient = c("moisture", "sweetness", "calories"),
Lower = lower_bonf,
Upper = upper_bonf,
Width = upper_bonf - lower_bonf
)
cat("\nBonferroni-adjusted 95% Confidence Intervals:\n")
print(bonferroni_CIs)
# ---- Compare with R's built-in confint() ----
cat("\nBuilt-in confint(model) results:\n")
print(confint(model, level = 0.95))
data <- read.csv("hw06pr01.csv", header = TRUE, sep = ",")
names(data)
model <- lm(brand ~ moisture + sweetness + calories, data = data)
summary(model)
cat("Fitted Equation:\n")
cat("Y_hat = ", coef(model)[1],
" + ", coef(model)[2], " * X1 (moisture)",
" + ", coef(model)[3], " * X2 (sweetness)",
" + ", coef(model)[4], " * X3 (calories)\n", sep = "")
