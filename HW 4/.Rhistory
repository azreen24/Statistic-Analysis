if (all(dim(mat1) == dim(mat2))) {  # Ensure both rows and columns match
cat("Matrices", name1, "and", name2, "can be added (same dimensions:", dim(mat1)[1], "x", dim(mat1)[2], ").\n")
} else {
cat("Matrices", name1, "and", name2, "CANNOT be added (different dimensions).\n")
}
}
# Compare all matrices to check for possible additions
for (i in 1:(length(matrices) - 1)) {  # Loop only up to second-to-last element
for (j in (i + 1):length(matrices)) {  # Ensure j is always valid
check_addition(matrices[[i]], matrices[[j]], matrix_names[i], matrix_names[j])
}
}
# Explanation
cat("Only two pairs of matrices can be added together because matrix addition
requires that both matrices have the same dimensions.\n")
# Define confidence level
alpha <- 0.10  # 90% joint confidence level
g <- 4  # Number of confidence intervals
# Sample size
n <- nrow(data)
# Compute Mean Squared Error (MSE)
MSE <- summary(model)$sigma^2
# Compute the mean of X (Copiers)
Xbar <- mean(data$Copiers)
# Compute SXX (Sum of squared deviations from mean of X)
SXX <- sum((data$Copiers - Xbar)^2)
# Compute t critical value for Bonferroni correction
t_critical_bonf <- qt(1 - alpha / (2 * g), df = n-2)
# Function to calculate Bonferroni confidence interval at given X_h
bonf_confidence_interval <- function(X_h) {
# Compute predicted Y value
Y_hat <- coef(model)[1] + coef(model)[2] * X_h
# Compute standard error
SE_Y_hat <- sqrt(MSE * (1/n + (X_h - Xbar)^2 / SXX))
# Compute confidence interval bounds
margin_of_error <- t_critical_bonf * SE_Y_hat
lower_bound <- Y_hat - margin_of_error
upper_bound <- Y_hat + margin_of_error
return(c(lower_bound, upper_bound))
}
# Calculate joint confidence intervals for X_h = 2, 4, 6, 8
X_h_values <- c(2, 4, 6, 8)
Bonf_CI_results <- t(sapply(X_h_values, bonf_confidence_interval))
# Display results
colnames(Bonf_CI_results) <- c("Lower Bound", "Upper Bound")
rownames(Bonf_CI_results) <- paste("X_h =", X_h_values)
print(Bonf_CI_results)
data <- read.csv("hw04pr01.csv", header = TRUE, sep = ",")
names(data)
# Fit simple linear regression model
model <- lm(Minutes ~ Copiers, data = data)
# summary of the model
summary(model)
# Extract coefficients
b0 <- coef(model)[1]  # Intercept
b1 <- coef(model)[2]  # Slope
# Print fitted equation
cat("Fitted Equation: Y (Minutes) =", round(b0, 2), "+", round(b1, 2), "* X (Copiers)\n")
# Define confidence level
alpha <- 0.10  # 90% confidence level
# Sample size
n <- nrow(data)
# Compute Mean Squared Error (MSE)
MSE <- summary(model)$sigma^2
# Compute the mean of X (Copiers)
Xbar <- mean(data$Copiers)
# Compute SXX (Sum of squared deviations from mean of X)
SXX <- sum((data$Copiers - Xbar)^2)
# Compute t critical value for (1 - alpha/2) confidence level
t_critical <- qt(1 - alpha/2, df = n-2)
# Function to calculate confidence interval at given X_h
confidence_interval <- function(X_h) {
# Compute predicted Y value
Y_hat <- coef(model)[1] + coef(model)[2] * X_h
# Compute standard error
SE_Y_hat <- sqrt(MSE * (1/n + (X_h - Xbar)^2 / SXX))
# Compute confidence interval bounds
lower_bound <- Y_hat - t_critical * SE_Y_hat
upper_bound <- Y_hat + t_critical * SE_Y_hat
return(c(lower_bound, upper_bound))
}
# Calculate confidence intervals for X_h = 2, 4, 6, 8
X_h_values <- c(2, 4, 6, 8)
CI_results <- t(sapply(X_h_values, confidence_interval))
# Display results
colnames(CI_results) <- c("Lower Bound", "Upper Bound")
rownames(CI_results) <- paste("X_h =", X_h_values)
print(CI_results)
# Interpretation at X_h = 4
X_selected <- 4
CI_selected <- confidence_interval(X_selected)
cat("We are 90% confident that the true mean service time\n",
"for servicing", X_selected, "copiers is between\n",
round(CI_selected[1], 2), "and", round(CI_selected[2], 2),
"minutes.\n")
# Define confidence level
alpha <- 0.10  # 90% joint confidence level
g <- 4  # Number of confidence intervals
# Sample size
n <- nrow(data)
# Compute Mean Squared Error (MSE)
MSE <- summary(model)$sigma^2
# Compute the mean of X (Copiers)
Xbar <- mean(data$Copiers)
# Compute SXX (Sum of squared deviations from mean of X)
SXX <- sum((data$Copiers - Xbar)^2)
# Compute t critical value for Bonferroni correction
t_critical_bonf <- qt(1 - alpha / (2 * g), df = n-2)
# Function to calculate Bonferroni confidence interval at given X_h
bonf_confidence_interval <- function(X_h) {
# Compute predicted Y value
Y_hat <- coef(model)[1] + coef(model)[2] * X_h
# Compute standard error
SE_Y_hat <- sqrt(MSE * (1/n + (X_h - Xbar)^2 / SXX))
# Compute confidence interval bounds
margin_of_error <- t_critical_bonf * SE_Y_hat
lower_bound <- Y_hat - margin_of_error
upper_bound <- Y_hat + margin_of_error
return(c(lower_bound, upper_bound))
}
# Calculate joint confidence intervals for X_h = 2, 4, 6, 8
X_h_values <- c(2, 4, 6, 8)
Bonf_CI_results <- t(sapply(X_h_values, bonf_confidence_interval))
# Display results
colnames(Bonf_CI_results) <- c("Lower Bound", "Upper Bound")
rownames(Bonf_CI_results) <- paste("X_h =", X_h_values)
print(Bonf_CI_results)
# Define confidence level
alpha <- 0.10  # 90% joint confidence level
g <- 4  # Number of confidence intervals
# Sample size
n <- nrow(data)
# Compute Mean Squared Error (MSE)
MSE <- sum(residuals(model)^2) / (n - 2)  # Corrected MSE calculation
# Compute the mean of X (Copiers)
Xbar <- mean(data$Copiers)
# Compute SXX (Sum of squared deviations from mean of X)
SXX <- sum((data$Copiers - Xbar)^2)
# Compute t critical value for Bonferroni correction
t_critical_bonf <- qt(1 - alpha / (2 * g), df = n - 2)
# Function to calculate Bonferroni confidence interval at given X_h
bonf_confidence_interval <- function(X_h) {
# Compute predicted Y value
Y_hat <- coef(model)[1] + coef(model)[2] * X_h
# Compute standard error
SE_Y_hat <- sqrt(MSE * (1/n + ((X_h - Xbar)^2 / SXX)))
# Compute confidence interval bounds
margin_of_error <- t_critical_bonf * SE_Y_hat
lower_bound <- Y_hat - margin_of_error
upper_bound <- Y_hat + margin_of_error
return(c(lower_bound, upper_bound))
}
# Calculate joint confidence intervals for X_h = 2, 4, 6, 8
X_h_values <- c(2, 4, 6, 8)
Bonf_CI_results <- t(sapply(X_h_values, bonf_confidence_interval))
# Display results
colnames(Bonf_CI_results) <- c("Lower Bound", "Upper Bound")
rownames(Bonf_CI_results) <- paste("X_h =", X_h_values)
print(Bonf_CI_results)
# Define confidence level
alpha <- 0.10  # 90% confidence level
# Sample size
n <- nrow(data)
# Compute Mean Squared Error (MSE)
MSE <- sum(residuals(model)^2) / (n - 2)  # Corrected MSE calculation
# Compute the mean of X (Copiers)
Xbar <- mean(data$Copiers)
# Compute SXX (Sum of squared deviations from mean of X)
SXX <- sum((data$Copiers - Xbar)^2)
# Compute F critical value for Working-Hotelling procedure
F_critical_wh <- qf(1 - alpha, df1 = 2, df2 = n-2)
# Function to calculate Working-Hotelling confidence interval at given X_h
wh_confidence_interval <- function(X_h) {
# Compute predicted Y value
Y_hat <- coef(model)[1] + coef(model)[2] * X_h
# Compute standard error
SE_Y_hat <- sqrt(MSE * (1/n + ((X_h - Xbar)^2 / SXX)))
# Compute confidence interval bounds
margin_of_error <- sqrt(2 * F_critical_wh) * SE_Y_hat
lower_bound <- Y_hat - margin_of_error
upper_bound <- Y_hat + margin_of_error
return(c(lower_bound, upper_bound))
}
# Calculate joint confidence intervals for X_h = 2, 4, 6, 8
WH_CI_results <- t(sapply(X_h_values, wh_confidence_interval))
# Display results
colnames(WH_CI_results) <- c("Lower Bound", "Upper Bound")
rownames(WH_CI_results) <- paste("X_h =", X_h_values)
print(WH_CI_results)
# Define the confidence intervals from Parts (b), (c), and (d)
CI_b <- matrix(c(26.11796, 32.86272,
57.15175, 61.96992,
87.28387, 91.97880,
116.46245, 122.94121),
ncol = 2, byrow = TRUE)
CI_c <- matrix(c(24.83096, 34.14972,
56.23236, 62.88931,
86.38800, 92.87466,
115.22620, 124.17745),
ncol = 2, byrow = TRUE)
CI_d <- matrix(c(25.06746, 33.91321,
56.40131, 62.72036,
86.55263, 92.71003,
115.45338, 123.95028),
ncol = 2, byrow = TRUE)
# Compute Confidence Interval Widths
width_b <- CI_b[,2] - CI_b[,1]  # Part (b)
width_c <- CI_c[,2] - CI_c[,1]  # Part (c)
width_d <- CI_d[,2] - CI_d[,1]  # Part (d)
# Create a dataframe to display the widths
X_h_values <- c(2, 4, 6, 8)
CI_widths <- data.frame(
X_h = X_h_values,
Width_b = width_b,
Width_c = width_c,
Width_d = width_d
)
# Print results
print(CI_widths)
# Comparison
cat("Bonferroni (Part c) produces the widest confidence intervals at every X_h.
Individual CIs (Part b) are the narrowest and Working-Hotelling (Part d) produces
slightly narrower intervals than Bonferroni.")
# Fit a linear regression through the origin (no intercept)
model_origin <- lm(Minutes ~ 0 + Copiers, data = data)
# Display model summary
summary(model_origin)
# Extract the coefficient (slope)
b1_origin <- coef(model_origin)[1]
# Print fitted equation
cat("Fitted Equation: Y (Minutes) =", round(b1_origin, 2), "* X (Copiers)\n")
# Get predicted values
Y_pred_origin <- predict(model_origin)
# Compute residuals
residuals_origin <- data$Minutes - Y_pred_origin
# Check if residuals sum to zero
residuals_sum <- sum(residuals_origin)
# Print sum of residuals
cat("Sum of residuals:", residuals_sum, "does not equal 0")
# Create scatterplot with both regression lines
ggplot(data, aes(x = ACT, y = GPA)) +
geom_point(color = "black", alpha = 0.6) +  # Scatterplot points
geom_abline(
intercept = b0, slope = b1,
color = "green", linewidth = 1, linetype = "solid"
) +  # Regular regression
geom_abline(
intercept = 0, slope = b1_origin,
color = "red", linewidth = 1, linetype = "dashed"
) +  # Regression through origin
labs(
title = "GPA vs. ACT Score with Both Regression Models",
x = "ACT Score",
y = "GPA"
) +
theme_minimal() +
annotate("text", x = 20, y = 3.5, label = "Regular Regression", color = "green") +
annotate("text", x = 20, y = 3.0, label = "Through-Origin Regression", color = "red")
data <- read.csv("hw04pr01.csv", header = TRUE, sep = ",")
names(data)
# Fit simple linear regression model
model <- lm(Minutes ~ Copiers, data = data)
# summary of the model
summary(model)
# Extract coefficients
b0 <- coef(model)[1]  # Intercept
b1 <- coef(model)[2]  # Slope
# Print fitted equation
cat("Fitted Equation: Y (Minutes) =", round(b0, 2), "+", round(b1, 2), "* X (Copiers)\n")
# Define confidence level
alpha <- 0.10
# Sample size
n <- nrow(data)
# Compute MSE
MSE <- sum(residuals(model)^2) / (n - 2)
# Compute the mean of X (Copiers)
Xbar <- mean(data$Copiers)
# Compute SXX
SXX <- sum((data$Copiers - Xbar)^2)
# Compute t critical value for (1 - alpha/2) confidence level
t_critical <- qt(1 - alpha/2, df = n-2)
# Function to calculate confidence interval at given X_h
confidence_interval <- function(X_h) {
# Compute predicted Y value
Y_hat <- coef(model)[1] + coef(model)[2] * X_h
# Compute standard error
SE_Y_hat <- sqrt(MSE * (1/n + ((X_h - Xbar)^2 / SXX)))
# Compute confidence interval bounds
margin_of_error <- t_critical * SE_Y_hat
lower_bound <- Y_hat - margin_of_error
upper_bound <- Y_hat + margin_of_error
return(c(lower_bound, upper_bound))
}
# Calculate confidence intervals for X_h = 2, 4, 6, 8
X_h_values <- c(2, 4, 6, 8)
CI_results <- t(sapply(X_h_values, confidence_interval))
# Results
colnames(CI_results) <- c("Lower Bound", "Upper Bound")
rownames(CI_results) <- paste("X_h =", X_h_values)
print(CI_results)
# Interpretation at X_h = 4
X_selected <- 4
CI_selected <- confidence_interval(X_selected)
cat("We are 90% confident that the true mean service time\n",
"for servicing", X_selected, "copiers is between\n",
round(CI_selected[1], 2), "and", round(CI_selected[2], 2),
"minutes.\n")
# Define confidence level
alpha <- 0.10
g <- 4
# Sample size
n <- nrow(data)
# Compute MSE
MSE <- sum(residuals(model)^2) / (n - 2)
# Compute the mean of X (Copiers)
Xbar <- mean(data$Copiers)
# Compute SXX
SXX <- sum((data$Copiers - Xbar)^2)
# Compute t critical value for Bonferroni correction
t_critical_bonf <- qt(1 - alpha / (2 * g), df = n - 2)
# Function to calculate Bonferroni confidence interval at given X_h
bonf_confidence_interval <- function(X_h) {
# Compute predicted Y value
Y_hat <- coef(model)[1] + coef(model)[2] * X_h
# Compute standard error
SE_Y_hat <- sqrt(MSE * (1/n + ((X_h - Xbar)^2 / SXX)))
# Compute confidence interval bounds
margin_of_error <- t_critical_bonf * SE_Y_hat
lower_bound <- Y_hat - margin_of_error
upper_bound <- Y_hat + margin_of_error
return(c(lower_bound, upper_bound))
}
# Calculate joint confidence intervals for X_h = 2, 4, 6, 8
X_h_values <- c(2, 4, 6, 8)
Bonf_CI_results <- t(sapply(X_h_values, bonf_confidence_interval))
# Results
colnames(Bonf_CI_results) <- c("Lower Bound", "Upper Bound")
rownames(Bonf_CI_results) <- paste("X_h =", X_h_values)
print(Bonf_CI_results)
# Define confidence level
alpha <- 0.10  # 90% confidence level
# Sample size
n <- nrow(data)
# Compute MSE
MSE <- sum(residuals(model)^2) / (n - 2)
# Compute the mean of X (Copiers)
Xbar <- mean(data$Copiers)
# Compute SXX
SXX <- sum((data$Copiers - Xbar)^2)
# Compute F critical value for Working-Hotelling procedure
F_critical_wh <- qf(1 - alpha, df1 = 2, df2 = n-2)
# Function to calculate Working-Hotelling confidence interval at given X_h
wh_confidence_interval <- function(X_h) {
# Compute predicted Y value
Y_hat <- coef(model)[1] + coef(model)[2] * X_h
# Compute standard error
SE_Y_hat <- sqrt(MSE * (1/n + ((X_h - Xbar)^2 / SXX)))
# Compute confidence interval bounds
margin_of_error <- sqrt(2 * F_critical_wh) * SE_Y_hat
lower_bound <- Y_hat - margin_of_error
upper_bound <- Y_hat + margin_of_error
return(c(lower_bound, upper_bound))
}
# Calculate joint confidence intervals for X_h = 2, 4, 6, 8
WH_CI_results <- t(sapply(X_h_values, wh_confidence_interval))
# Display results
colnames(WH_CI_results) <- c("Lower Bound", "Upper Bound")
rownames(WH_CI_results) <- paste("X_h =", X_h_values)
print(WH_CI_results)
# Define the confidence intervals from Parts (b), (c), and (d)
CI_b <- matrix(c(26.11796, 32.86272,
57.15175, 61.96992,
87.28387, 91.97880,
116.46245, 122.94121),
ncol = 2, byrow = TRUE)
CI_c <- matrix(c(24.83096, 34.14972,
56.23236, 62.88931,
86.38800, 92.87466,
115.22620, 124.17745),
ncol = 2, byrow = TRUE)
CI_d <- matrix(c(25.06746, 33.91321,
56.40131, 62.72036,
86.55263, 92.71003,
115.45338, 123.95028),
ncol = 2, byrow = TRUE)
# Compute Confidence Interval Widths
width_b <- CI_b[,2] - CI_b[,1]  # Part (b)
width_c <- CI_c[,2] - CI_c[,1]  # Part (c)
width_d <- CI_d[,2] - CI_d[,1]  # Part (d)
# Create a dataframe to display the widths
X_h_values <- c(2, 4, 6, 8)
CI_widths <- data.frame(
X_h = X_h_values,
Width_b = width_b,
Width_c = width_c,
Width_d = width_d
)
# Print results
print(CI_widths)
# Comparison
cat("Bonferroni (Part c) produces the widest confidence intervals at every X_h.
Individual CIs (Part b) are the narrowest and Working-Hotelling (Part d) produces
slightly narrower intervals than Bonferroni.")
# Fit a linear regression through the origin (no intercept)
model_origin <- lm(Minutes ~ 0 + Copiers, data = data)
# Display model summary
summary(model_origin)
# Extract the coefficient (slope)
b1_origin <- coef(model_origin)[1]
# Print fitted equation
cat("Fitted Equation: Y (Minutes) =", round(b1_origin, 2), "* X (Copiers)\n")
# Get predicted values
Y_pred_origin <- predict(model_origin)
# Compute residuals
residuals_origin <- data$Minutes - Y_pred_origin
# Check if residuals sum to zero
residuals_sum <- sum(residuals_origin)
# Print sum of residuals
cat("Sum of residuals:", residuals_sum, "does not equal 0")
# Load library
library(ggplot2)
# Load dataset
data <- read.csv("hw04pr02.csv")
head(data)
# Fit a regular linear regression model (with intercept)
model <- lm(GPA ~ ACT, data = data)
# Display model summary
summary(model)
# Extract coefficients
b0 <- coef(model)[1]  # Intercept
b1 <- coef(model)[2]  # Slope
# Print estimated regression function
cat("Estimated Regression Function: Y =", round(b0, 2), "+", round(b1, 2), "* X (ACT Score)\n")
# Fit linear regression through the origin (no intercept)
model_origin <- lm(GPA ~ 0 + ACT, data = data)
# Display model summary
summary(model_origin)
# Extract slope coefficient (no intercept)
b1_origin <- coef(model_origin)[1]
# Print estimated regression function
cat("Estimated Regression Function (Through Origin): Y =", round(b1_origin, 2), "* X (ACT Score)\n")
# Create scatterplot with both regression lines
ggplot(data, aes(x = ACT, y = GPA)) +
geom_point(color = "black", alpha = 0.6) +  # Scatterplot points
geom_abline(
intercept = b0, slope = b1,
color = "green", linewidth = 1, linetype = "solid"
) +  # Regular regression
geom_abline(
intercept = 0, slope = b1_origin,
color = "red", linewidth = 1, linetype = "dashed"
) +  # Regression through origin
labs(
title = "GPA vs. ACT Score with Both Regression Models",
x = "ACT Score",
y = "GPA"
) +
theme_minimal() +
annotate("text", x = 20, y = 3.5, label = "Regular Regression", color = "green") +
annotate("text", x = 20, y = 3.0, label = "Through-Origin Regression", color = "red")
# Store matrices in a named list
matrices <- list(A=A, B=B, C=C, D=D, A_t=A_t, B_t=B_t, C_t=C_t, D_t=D_t)
# Function to check matrix addition compatibility
check_addition <- function(pair) {
mat1 <- matrices[[pair[1]]]
mat2 <- matrices[[pair[2]]]
if (all(dim(mat1) == dim(mat2))) {
cat("Matrices", pair[1], "and", pair[2], "can be added (same dimensions:", dim(mat1)[1], "x", dim(mat1)[2], ").\n")
} else {
cat("Matrices", pair[1], "and", pair[2], "CANNOT be added (different dimensions).\n")
}
}
# Generate all unique pairs of matrices
matrix_pairs <- combn(names(matrices), 2, simplify = FALSE)
# Apply the function to all pairs
invisible(lapply(matrix_pairs, check_addition))
# Explanation
cat("Only two pairs of the matrices in this example can be added together\n")
cat("because matrix addition requires that both matrices\n")
cat("have the same dimensions.\n")
# Store matrices in a named list
matrices <- list(A=A, B=B, C=C, D=D, A_t=A_t, B_t=B_t, C_t=C_t, D_t=D_t)
# Identify which matrices can be added
valid_additions <- combn(names(matrices), 2, simplify = FALSE) |>
Filter(function(pair) all(dim(matrices[[pair[1]]]) == dim(matrices[[pair[2]]])))
# Store matrices in a named list
matrices <- list(A=A, B=B, C=C, D=D, A_t=A_t, B_t=B_t, C_t=C_t, D_t=D_t)
# Generate all unique pairs of matrices
matrix_pairs <- combn(names(matrices), 2, simplify = FALSE)
# Function to check valid additions
valid_additions <- lapply(matrix_pairs, function(pair) {
if (all(dim(matrices[[pair[1]]]) == dim(matrices[[pair[2]]]))) {
return(pair)
} else {
return(NULL)
}
})
# Filter out NULL values (invalid additions)
valid_additions <- Filter(Negate(is.null), valid_additions)
# Print results
if (length(valid_additions) > 0) {
cat("The following matrix pairs can be added together:\n")
for (pair in valid_additions) {
cat(pair[1], "and", pair[2], "(Dimensions:", dim(matrices[[pair[1]]])[1], "x", dim(matrices[[pair[1]]])[2], ")\n")
}
} else {
cat("No matrices can be added together as none share the same dimensions.\n")
}
# Explanation
cat("Only two pairs of the matrices in this example can be added together\n")
cat("because matrix addition requires that both matrices\n")
cat("have the same dimensions.\n")
